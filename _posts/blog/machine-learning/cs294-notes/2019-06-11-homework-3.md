---
layout: post
title: Homework 3
permalink: blog/machine-learning/cs294-notes/homework-3
categories: [Machine Learning, CS294 Notes]
---

Note: To replicate results in this report run the script files in the hw3 directory in [this](https://github.com/shehryar-malik/UC-Berkeley-CS294-DeepRL/tree/master/hw3) repository.

### Q-Learning

**Problem 1**

I am still trying to arrange for some computational resources to run this problem. My laptop seems to be too old to run this kind of experiment :(

**Problem 2**

The following graph plots the average rewards for both the double Q-learning and vanilla Q-learning algorithms on the Lunar Lander game.![]({{site.baseurl}}\assets\blog\images\cs294-notes\a3_dqn_2_vdql_ll.png)

Clearly, double Q-learning performs much better than vanilla Q-learning.

**Problem 3**

We experiment with the learning rate. The graph below shows the average rewards plotted for four different settings of the learning rate for the Lunar Lander game.![]({{site.baseurl}}\assets\blog\images\cs294-notes\a3_dqn_3_lr_ll.png)

It can be seen from the graph that a high learning rate (0.1) decreases the average rewards significantly. As the learning rate is lowered from 0.1 to 0.001 the average rewards increase. However, further lowering the learning rate to 0.0001 decreases the average rewards.

### Actor-Critic Algorithm

**Problem 1**![]({{site.baseurl}}\assets\blog\images\cs294-notes\a3_ac_p1.png)

**Problem 2: Inverted Pendulum** ![]({{site.baseurl}}\assets\blog\images\cs294-notes\a3_ac_p2_a.png)

**Problem 2: Half Cheetah** ![]({{site.baseurl}}\assets\blog\images\cs294-notes\a3_ac_p2_b.png)
